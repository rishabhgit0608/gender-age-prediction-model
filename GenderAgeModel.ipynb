{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"iEamDXqvWTDw"},"outputs":[],"source":["import pandas as pd\n","import numpy as np \n","import os\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","from tqdm.notebook import tqdm \n","warnings.filterwarnings('ignore')\n","%matplotlib inline \n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.models import Sequential,Model\n","from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ephsc5Go1KiP"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GS32ILL0GLbN"},"outputs":[],"source":["BASE_DIR = '/home/nirvana/Downloads/UTKFace-20220520T032559Z-001/UTKFace'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mwqV5MPwXOqg"},"outputs":[],"source":["image_paths = [] \n","age_labels = []\n","gender_labels =[] \n","\n","for filename in tqdm(os.listdir(BASE_DIR)):\n","  image_path = os.path.join(BASE_DIR,filename)\n","  temp = filename.split('_')\n","  age = int(temp[0])\n","  gender = int(temp[1])\n","  image_paths.append(image_path)\n","  age_labels.append(age)\n","  gender_labels.append(gender)"]},{"cell_type":"markdown","metadata":{"id":"c1d-z6X6GS-y"},"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oKzdz_yd1onY"},"outputs":[],"source":["# convert to dataframe \n","df = pd.DataFrame()\n","df['image'],df['age'],df['gender'] = image_paths,age_labels,gender_labels\n","df.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VjXbxntmKMvQ"},"outputs":[],"source":["# map labels for gender \n","gender_dict = {0:'Male',1:'Female'}\n"]},{"cell_type":"markdown","metadata":{"id":"pgYAi9A6ONu6"},"source":["Exploratory data analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VV-rNQpFOHii"},"outputs":[],"source":["from PIL import Image\n","img = Image.open(df['image'][0])\n","plt.axis('off')\n","plt.imshow(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-VNj_N-UOeIw"},"outputs":[],"source":["sns.distplot(df['age'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"htVRzgFvb6X4"},"outputs":[],"source":["sns.countplot(df['gender'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Vny9mHmcH1r"},"outputs":[],"source":["#to display grid of images\n","plt.figure(figsize=(20,20))\n","files = df.iloc[0:25]\n","\n","for index,file,age,gender in files.itertuples():\n","  plt.subplot(5,5,index+1)\n","  img = load_img(file)\n","  img = np.array(img)\n","  plt.imshow(img)\n","  plt.title(f\"Age:{age} Gender:{gender_dict[gender]}\")\n","  plt.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5Usq_YxcR6K"},"outputs":[],"source":["## Feature extraction "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YIkSM137d9fr"},"outputs":[],"source":["def extract_features(images):\n","  features = [] \n","  for image in tqdm(images):\n","    img = load_img(image,grayscale=True)\n","    img = img.resize((128,128),Image.ANTIALIAS)\n","    img = np.array(img)\n","    features.append(img)\n","\n","  features=np.array(features)\n","  features=features.reshape(len(features),128,128,1)\n","  return features\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b5V7EL-1h3_R"},"outputs":[],"source":["X = extract_features(df['image'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"63230B4ZiE6X"},"outputs":[],"source":["X.shape "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BMnHK7uoiXWR"},"outputs":[],"source":["# Normalize the images \n","X = X/255.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"anO4HLNUihnj"},"outputs":[],"source":["y_gender = np.array(df['gender'])\n","y_age = np.array(df['age'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ayzSdlqgiwkE"},"outputs":[],"source":["input_shape = (128,128,1)"]},{"cell_type":"markdown","metadata":{"id":"-TItMSyki5wD"},"source":["## model creation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6K-87rWNi7az"},"outputs":[],"source":["inputs = Input((input_shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uXtWQfH-jCat"},"outputs":[],"source":["conv_1 = Conv2D(32,kernel_size=(3,3),activation='relu')(inputs)\n","maxp_1 = MaxPooling2D(pool_size=(2,2))(conv_1)\n","conv_2 = Conv2D(64,kernel_size=(3,3),activation='relu')(maxp_1)\n","maxp_2 = MaxPooling2D(pool_size=(2,2))(conv_2)\n","conv_3 = Conv2D(128,kernel_size=(3,3),activation='relu')(maxp_2)\n","maxp_3 = MaxPooling2D(pool_size=(2,2))(conv_3)\n","conv_4 = Conv2D(256,kernel_size=(3,3),activation='relu')(maxp_3)\n","maxp_4 = MaxPooling2D(pool_size=(2,2))(conv_4)\n","\n","flatten = Flatten() (maxp_4)\n","\n","# fully connected layers \n","dense_1 = Dense(256,activation='relu') (flatten)\n","dense_2 = Dense(256,activation='relu') (flatten)\n","\n","dropout_1 = Dropout(0.3) (dense_1)\n","dropout_2 = Dropout(0.3) (dense_2)\n","\n","output_1 = Dense(1, activation = 'sigmoid',name ='gender_out') (dropout_1)\n","output_2 = Dense(1, activation = 'relu',name ='age_out') (dropout_2)\n","\n","model = Model(inputs =[inputs],outputs=[output_1,output_2])\n","\n","model.compile(loss = ['binary_crossentropy','mae'],optimizer='adam',metrics=['accuracy'])\n"," \n"]},{"cell_type":"code","source":[""],"metadata":{"id":"DuokyK9SemEW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eMUvcUvOjJYS"},"outputs":[],"source":["from tensorflow.keras.utils import plot_model\n","plot_model(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kiYp4QRQuZN0"},"outputs":[],"source":["history = model.fit(x=X,y=[y_gender,y_age],batch_size=32,epochs=30,validation_split=0.2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4rVrIkA7vB6P"},"outputs":[],"source":["image_index = 2\n","print('Original Gender:',gender_dict[y_gender[image_index]],\"Original Age\",y_age[image_index])\n","pred = model.predict(X[image_index].reshape(1,128,128,1))\n","pred_gender = gender_dict[round(pred[0][0][0])]\n","pred_age = round(pred[1][0][0])\n","print(\"predicted_gender:\",pred_gender,\"predicted_age:\",pred_age)\n","plt.axis('off')\n","plt.imshow(X[image_index].reshape(128,128),cmap='gray');"]},{"cell_type":"code","source":[""],"metadata":{"id":"sEyfL34sfMPZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"6Qkbn2ZYhfwy"}}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"name":"GenderAgeModel.ipynb","provenance":[],"toc_visible":true,"private_outputs":true,"authorship_tag":"ABX9TyOu3mUvUBmXO7Xwa9g6b77G"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}